{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links:\n",
    "- [Dataset documentation](https://nijianmo.github.io/amazon/index.html)\n",
    "- [Complete Metadata files](http://deepyeti.ucsd.edu/jianmo/amazon/index.html)\n",
    "- [Pandas reference sheet](https://ds100.org/sp21/resources/assets/exams/sp20/sp20_checkpoint_reference_sheet.pdf)\n",
    "- [Data-200 Google Doc](https://docs.google.com/document/d/19HWODy5kpWoUB7BEKEmKLbRnK8MC1fBmRat_WP7vfNc/edit)\n",
    "- [Grad Project Guidelines](https://ds100.org/sp21/grad_proj/gradproject/)\n",
    "- [Git repo](https://github.com/alexander-zw/data200-proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gzip\n",
    "import urllib.request\n",
    "import seaborn as sns\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Software_5.json.gz\"\n",
    "filename = 'Softwares.json.gz'\n",
    "if not os.path.exists(filename):\n",
    "    urllib.request.urlretrieve(url,filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the data\n",
    "\n",
    "data = []\n",
    "with gzip.open(filename) as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of reviews\n",
    "print(len(data))\n",
    "\n",
    "# first row of the list\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame.from_dict(data)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check score-wise values\n",
    "reviews[(reviews['overall'] == 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column labels:\n",
    "- reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "- asin - ID of the product, e.g. 0000013714\n",
    "- reviewerName - name of the reviewer\n",
    "- vote - helpful votes of the review\n",
    "- style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "- reviewText - text of the review\n",
    "- overall - rating of the product\n",
    "- summary - summary of the review\n",
    "- unixReviewTime - time of the review (unix time)\n",
    "- reviewTime - time of the review (raw)\n",
    "- image - images that users post after they have received the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking 5-core:\n",
    "A 5-core dataset contains only those users with at least 5 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['reviewerID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.query(\"reviewerID in ['A2AEZQ3DGBBLPR','A1PPD5TOR6VVYV','A3FGJDBSMCSG7G']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles/meta_Software.json.gz\"\n",
    "filename = 'Meta_Softwares.json.gz'\n",
    "if not os.path.exists(filename):\n",
    "    urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the data\n",
    "\n",
    "data = []\n",
    "with gzip.open(filename) as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of products\n",
    "print(len(data))\n",
    "\n",
    "# first row of the list\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame.from_dict(data)\n",
    "metadata.head()\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['asin'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the reviews and metadata on `asin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reviews.merge(metadata,how=\"left\",on = \"asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column labels:\n",
    "- asin - ID of the product, e.g. 0000031852\n",
    "- title - name of the product\n",
    "- feature - bullet-point format features of the product\n",
    "- description - description of the product\n",
    "- price - price in US dollars (at time of crawl)\n",
    "- image - url of the product image\n",
    "- related - related products (also bought, also viewed, bought together, buy after viewing)\n",
    "- salesRank - sales rank information\n",
    "- brand - brand name\n",
    "- categories - list of categories the product belongs to\n",
    "- tech1 - the first technical detail table of the product\n",
    "- tech2 - the second technical detail table of the product\n",
    "- similar - similar product table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can clean the data a little: \n",
    "- Change `overall` column name to `rating`\n",
    "- `asin` to `productid`\n",
    "- Extract `gift_amount` from `style`\n",
    "- Extract `rank#` from `rank`\n",
    "- Rempve rows with no information on the price either from `price` column or from `gift_amount` as both should be the same\n",
    "- `price` missing? Change dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and filtering and EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Remove rows with unformatted title (i.e. some 'title' may still contain html style content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.fillna('')\n",
    "df4 = df3[df3.title.str.contains('getTime')] # unformatted rows\n",
    "df5 = df3[~df3.title.str.contains('getTime')] # filter those unformatted rows\n",
    "df = df5\n",
    "print(len(df3))\n",
    "print(len(df5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check if there are products with missing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[metadata['price']==''].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, products with missing price do exist. We now decide on whether we remove these products from the review dataset or we keep them and try coming up with a approximation for their price.\n",
    "Let's check what proportion of the product dataset is missing a price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"About \",metadata[metadata['price']==''].shape[0]/metadata.shape[0] * 100,\"% products are missing a price value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proportion is very huge. Let's see if we can identify a pattern in the product metadata for missing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprice = metadata[metadata['price'] =='']\n",
    "withprice = metadata[metadata['price'] !='']\n",
    "brands_no_price = noprice['brand'].value_counts(dropna=False).to_frame().reset_index()\n",
    "brands_no_price.columns = ['brand','no_price']\n",
    "brands_with_price = withprice['brand'].value_counts(dropna=False).to_frame().reset_index()\n",
    "brands_with_price.columns = ['brand','with_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if not having prices is a brand specific pattern or product specific. If this is not specific to a brand, we can use the average price for all the products of a brand to assign the missing price. Unfortuately, if there is a brand with no products priced, we will have to discard that data as the proportion of products with missing price data is already very big and making assumptions will skew the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`price_exist` is a dataframe with `brand` name,`total` # products, # products with price (`with_price`), # products without price(`no_price`) and a boolean feature which is `True` if the brand has both priced and unpriced products otherwies `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_exist = metadata['brand'].value_counts(dropna=False).to_frame().reset_index()\n",
    "price_exist.columns = ['brand','total']\n",
    "price_exist.head()\n",
    "\n",
    "price_exist = price_exist.merge(brands_with_price,how = 'left',on = 'brand').merge(brands_no_price,how = 'left',on = 'brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_exist.head()\n",
    "price_exist.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems many brands have more products with no price in the dataset than otherwise. Let's see if the product itself is free on Amazon or if the dataset has missing data. Looking at products sold by Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.query(\"brand == 'Microsoft'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', )  \n",
    "print(metadata.query(\"brand== 'Microsoft'\").loc[69,'description'],\"\\n\")\n",
    "print(metadata.query(\"brand== 'Microsoft'\").loc[69,'title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking some of these products on Amazon.com, it appears that all these products offer outdated technologies. These products are \"Currently Unavailable\" on Amazon and have probably been so for a while since this dataset is about 3-4 years old.\n",
    "Let's see what does the plot for total products to products that are currently unavailable looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(price_exist['total'],price_exist['no_price']/price_exist['total'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this plot includes a lot of brands which only ever sold a few products and then shut down. Let's just look at the active brands. These are the brands which have atleast a few products with prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = price_exist['with_price']>10\n",
    "x = price_exist.loc[filtered,'total']\n",
    "y = price_exist.loc[filtered,'no_price']/price_exist.loc[filtered,'total']\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's just look at brands that sell more than a 100 products and are currently active.\n",
    "We update our filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = (price_exist['with_price']>10) & (price_exist['total']>100)\n",
    "x = price_exist.loc[filtered,'total']\n",
    "y = price_exist.loc[filtered,'no_price']/price_exist.loc[filtered,'total']\n",
    "plt.scatter(x,y)\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see that most of these brands have more unavailable products than available products (i.e. proportion > 0.5). This clearly is an indicator of how quickly the inventory evolves especially in the tech/software field. The right extreme marker is Microsoft. And with a total of roughly 1200 products it is only actively selling about 175."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Extracting the sentiment of the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed with extracting the sentiment from the reviews. We will then compare it with the rating and see what correlations we expect. One should expect a positive correlation. We will then compare sentiment against the prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall be using VADER. The cell below loads the data containing all sentiments into a dataframe called `sent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(open(\"vader_lexicon.txt\").readlines()[:10]))\n",
    "sent = pd.read_csv('vader_lexicon.txt',sep = '\\t',index_col=0,header=None, usecols = [0,1], names = ['token',\"polarity\"])\n",
    "sent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again look at the `reviews` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the `summary` and `reviewText`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead we need to first remove all the punctuation. Below is a regex which will capture all the punctuations within text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_re = r'[^\\w_\\s]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_texts(df):\n",
    "    punct_re = r'[^\\w_\\s\\n]'    \n",
    "    df[\"clean_text\"] = df['reviewText'].str.lower().str.replace(punct_re,\" \",regex = True)\n",
    "    df[\"clean_summary\"] = df['summary'].str.lower().str.replace(punct_re,\" \",regex = True)\n",
    "    return df\n",
    "\n",
    "reviews = sanitize_texts(reviews)\n",
    "reviews[\"clean_text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"unixReviewTime\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our review dataset doesn't have a primary key. Let's create one!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"primary_key\"] = reviews.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"primary_key\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ended up using the index as our primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tidy_format(df):\n",
    "    tidy = (\n",
    "        df[\"clean_text\"]\n",
    "        .str.split()\n",
    "        .explode()\n",
    "        .to_frame()\n",
    "        .rename(columns={\"clean_text\": \"word\"})\n",
    "    )\n",
    "    return tidy\n",
    "\n",
    "tidyReviewText = to_tidy_format(reviews)\n",
    "tidyReviewText.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in the Polarity Score\n",
    "\n",
    "Now that we have this table in the tidy format, it becomes much easier to find the sentiment of each review: we can join the table with the lexicon table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_polarity(df, tidy_df):\n",
    "    df[\"polarity\"] = (\n",
    "        tidy_df\n",
    "        .merge(sent, how='left', left_on='word', right_index=True)\n",
    "        .reset_index()\n",
    "        .loc[:, ['index', 'polarity']]\n",
    "        .groupby('index')\n",
    "        .sum()\n",
    "        .fillna(0)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "reviews = add_polarity(reviews, tidyReviewText)\n",
    "reviews.query(\"polarity<0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the polarity in place, let's see how polarity correlates with rating. We'll first do so without grouping by product and just focus on reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"overall\",y =\"polarity\",data = reviews)\n",
    "plt.ylim(-100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is wierd. One would expect that the polarity of reviews would go up as the rating increases. Indeed, this is the case till about 4.0 but then the boxplot distribution shows a dip. Let's compare the correlation now for verified and non-verified users separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"overall\",y =\"polarity\",data = reviews, hue = 'verified')\n",
    "plt.ylim(-100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the dip in rating comes from unverified users. Let's also see some of the 5.0 rating reviews with polarity <0. It may be possible that VADER may not have some of these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.query(\"(polarity<10) & (overall == 5)\").loc[:,['overall','reviewText','polarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the entries above it appears that these reviews are in general shorter in length. Which means that less polarity being added together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create similar plots but for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews = reviews[['asin','overall','polarity']].groupby(by = 'asin').agg(np.mean)\n",
    "product_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews.plot.scatter('overall','polarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at how price affects rating and polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprice_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprice_reviews = df.loc[df['price']=='',:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for their brands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(noprice_reviews['brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe `product` with only the relevant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
